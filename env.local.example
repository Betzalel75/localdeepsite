# LocalSite Configuration
# Copy this file to .env.local and fill in your API keys

# ==========================================
# LOCAL MODE CONFIGURATION
# ==========================================

# Set to "true" to enable local mode with Ollama
LOCAL_MODE=true
NEXT_PUBLIC_LOCAL_MODE=true

# Ollama Configuration (for local inference)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:7b

# ==========================================
# CLOUD API KEYS (Optional - for cloud inference)
# ==========================================

# DeepSeek API
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Google Gemini API
GEMINI_API_KEY=your_GEMINI_API_KEY_here

# OpenAI API (if you want to use GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude API
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Groq API
GROQ_API_KEY=your_groq_api_key_here

# Together AI API
TOGETHER_API_KEY=your_together_api_key_here

# Fireworks AI API
FIREWORKS_API_KEY=your_fireworks_api_key_here

# Hugging Face API (for fallback)
HF_TOKEN=your_huggingface_token_here
DEFAULT_HF_TOKEN=your_default_hf_token_here

# ==========================================
# DATABASE CONFIGURATION (Optional)
# ==========================================

# MongoDB URI (leave empty for local development without database)
MONGODB_URI=

# ==========================================
# OAUTH CONFIGURATION (for HuggingFace login - optional in local mode)
# ==========================================

OAUTH_CLIENT_ID=your_oauth_client_id
OAUTH_CLIENT_SECRET=your_oauth_client_secret

# ==========================================
# ADVANCED CONFIGURATION
# ==========================================

# LM Studio Configuration (alternative local provider)
LM_STUDIO_BASE_URL=http://localhost:1234

# LocalAI Configuration (another local provider)
LOCALAI_BASE_URL=http://localhost:8080

# Mixed mode - allow both local and cloud models
ENABLE
